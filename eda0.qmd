# Análisis Exploratorio de Datos {#sec-eda}

El análisis exploratorio de datos o (EDA, del inglés "Exploratory Data Analysis") representa un conjunto de técnicas que permiten resumir los aspectos más importantes de un conjunto de datos, normalmente con especial énfasis en el uso de métodos de visualización gráfica. El término fue popularizado, entre otros, por el estadístico norteamericano *John W. Tukey* como método para descubrir información importante (y no evidente) contenida en los datos [@tukey1977exploratory]. Estas técnicas se emplean habitualmente como paso previo a la inferencia estadística, orientada hacia un análisis confirmatorio. Así, con EDA se estudian los datos, se descubre cómo son y cómo se comportan y con la inferencia estadística se comprueba analíticamente si esos comportamientos y diferencias halladas son realmente significativos (desde un punto de vista estadístico). El EDA es, sin duda, fundamental para adquirir conocimiento de los datos, antes de emplearlos dentro de un modelo de Aprendizaje Automático como los que vais a aprender a lo largo del grado en Ciencia e Ingeniería de Datos. Es un error muy típico de algunos analistas de datos aplicar modelos a sus datos en cuanto estos están disponibles sin pasar previamente por el necesario análisis exploratorio de los mismos.

::: {.callout-tip title="John Tukey"}
"El análisis exploratorio de datos es una actitud, un estado de flexibilidad, una voluntad de buscar aquellas cosas que creemos que no están ahí, así como aquellas que creemos que están ahí."
:::

Es decir, el EDA no sigue un proceso formal con normas estrictas. Más bien, es una mentalidad o enfoque. En otras palabras, una forma de hacer las cosas. Cuando lleves a cabo un EDA, debes sentirte libre para explorar todas las ideas que se te ocurran. Algunas de estas ideas serán fructíferas, mientras que otras pueden llevarte a callejones sin salida. No te preocupes, probablemente no hayas roto nada. Simplemente habrás "gastado" tiempo. A medida que sigas explorando, te enfocarás en áreas particularmente prometedoras, las cuales documentarás y compartirás con otros.

A menudo se necesita mucho tiempo para explorar los datos. Se dice que el *80%* del tiempo del proyecto se gasta en EDA. A través del proceso de EDA, podemos pedir que se redefina el enunciado del problema o la definición de nuestro conjunto de datos, lo cual es muy importante.

::: {.callout-important title="Para recordar"}
Cuando nos enfrentamos a un EDA, lo ideal es contar con un objetivo que se haya definido junto con los datos, indicando qué se quiere conseguir a partir de ellos. Por ejemplo, "*predecir las ventas en los próximos 30 días*", "*estimar el riesgo que tiene un paciente de no superar una determinada operación quirúrgica*", "*clasificar como fraudulenta, o no, una página web*", etc.
:::

EDA es un ciclo iterativo:

1.  Genera preguntas sobre los datos.

2.  Busca respuestas visualizando, transformando y modelizando los datos.

3.  Utiliza lo que hayas aprendido para refinar las preguntas y/o generar otras nuevas.

## Preguntas

Tu objetivo principal durante el EDA es adquirir una comprensión profunda de los datos. La forma más sencilla de hacerlo es utilizar preguntas como herramientas para guiar la investigación. Cuando planteas una pregunta, ésta centra tu atención en una parte específica del conjunto de datos y te ayuda a decidir qué gráficos, modelos o transformaciones realizar.

EDA es un proceso creativo y como tal, la clave para llevarlo a cabo consiste en el planteamiento de preguntas de calidad. ¿Qué preguntas son las correctas? La respuesta es que depende del conjunto de datos con el que se trabaje.

::: {.callout-tip title="John Tukey"}
Mucho mejor una respuesta aproximada a la pregunta correcta, que a menudo es vaga, que una respuesta exacta a la pregunta incorrecta, que siempre se puede precisar
:::

Al inicio del análisis, puede resultar todo un desafío formular preguntas reveladoras, ya que aún no se conoce completamente la información contenida en el conjunto de datos. Sin embargo, cada nueva pregunta que plantees te llevará a explorar un nuevo aspecto de tus datos, aumentando así las posibilidades de hacer descubrimientos importantes.

::: {.callout-important title="Para recordar"}
Durante la preparación y limpieza de los datos acumulamos pistas sobre los modelos más adecuados que podrán ser aplicados en etapas posteriores.
:::

Algunas de las preguntas que, generalmente, deberían de abordarse durante el EDA son:

-   ¿Cuál es el tamaño de la base de datos? Es decir:

    -   ¿Cuántas observaciones hay?

    -   ¿Cuántas variables/características están medidas?

    -   ¿Disponemos de capacidad de cómputo en nuestra máquina para procesar la base de datos o necesitamos más recursos?

    -   ¿Existen valores faltantes?

-   ¿Qué tipo variables aparecen en la base de datos?

    -   ¿Qué variables son discretas?

    -   ¿Cuáles son continuas?

    -   ¿Qué categorías tienen las variables?

    -   ¿Hay variables tipo texto?

-   Variable objetivo: ¿Existe una variable de "respuesta"?

    -   ¿Binaria o multiclase?

-   ¿Es posible identificar variables irrelevantes?. Estudiar variables relevantes requiere, habitualmente, métodos estadísticos.

-   ¿Es posible identificar la distribución que siguen las variables?

-   Calcular estadísticos resumen (media, desviación típica, frecuencia,\...) de todas las variables de interés.

-   Detección y tratamiento de valores atípicos.

    -   ¿Son errores de media?

    -   ¿Podemos eliminarlos?

-   ¿Existe correlación entre variables?

::: {.callout-important title="Para recordar"}
Una correcta preparación y limpieza de datos implica, sin duda, un ahorro de tiempo en etapas posteriores del proyecto.
:::

Para repasar algunos de los métodos numéricos y gráficos que vamos a emplear en el análisis exploratorio de datos, vamos a dividir los siguientes apartados en función del tipo de variable.

## Variables cualitativas

Como se mencionó anteriormente, las variables cualitativas, o categóricas, describen atributos o cualidades. Una representación habitual de este tipo de varibles se consigue mediante la llamada **tabla de frecuencia**. La tabla de frecuencias es una representación en filas y columnas con la siguiente estructura:

-   una columna con cada uno de los valores $(x_i)$ o de las clases $(c_i)$

-   una columna con el recuento de elementos de cada clase $(n_i)$, que son las frecuencias absolutas.

-   se pueden añadir las frecuencias relativas $(f_i=n_i/n)$ y las acumuladas, tanto para las absolutas $(N_i)$ como para las relativas $(F_i)$.

::: {.callout-important title="Para recordar"}
Las frecuencias acumuladas solo tiene sentido para atributos en escala ordinal.
:::

El siguiente código obtiene la tabla de frecuencias absolutas para la varible estado civil de la base de datos `bank`.

```{r leer, echo=FALSE}
library(tidyverse)
bank = read.csv('https://raw.githubusercontent.com/rafiag/DTI2020/main/data/bank.csv')
bank=as.tibble(bank)
```

```{r tabla_frecuencias}
table(bank$marital)
```

Otro modo de conseguir el mismo resultado con la libraría `dplyr`

```{r freq}
freq_table <- bank %>%
   group_by(marital) %>%
   summarise(frequency = n()) %>%
   arrange(desc(frequency))
print(freq_table)
```

Si deseamos la frecuencia relativa:

```{r freq1}
freq_table <- bank %>%
   group_by(marital) %>%
   summarise(freq_relative = n()/dim(bank)[1]) %>%
   arrange(desc(freq_relative))
print(freq_table)
```

Esto es, en los datos de ejemplo, el `r round(100*freq_table$freq_relative[1],digits=2)` por ciento de las personas tienen el estado civil de "`r freq_table$marital[1]`".

Como principal representación gráfica asociada a las variables cualitativas podemos recomentar el **gráfico de barras**

Es un gráfico en el que se representa, en el eje $x$ las categorías y en el eje $y$ las frecuencias, bien relativas, bien absolutas. Por ejemplo, para la variable `marital` anterior tenemos:

```{r graf0, warning=FALSE}
barplot(table(bank$marital))
```

O en una opción más visualmente llamativa:

```{r graf1, warning=FALSE}
ggplot(data=bank,aes(x=marital,fill=marital)) +
  geom_bar(aes(y=(..count..)/sum(..count..))) +
  scale_y_continuous(labels=scales::percent) +
  theme(legend.position="none") +
  ylab("Frecuencia relativa") +
  xlab("Estado civil")
```

::: callout-caution
## Atención

¿Qué significado tienen los colores del gráfico anterior? ¿Son necesarios para el gráfico? Piensa sobre ello.
:::

## Variables cuantitativas

Recordemos que las variables cuantitativas son variables numéricas que pueden ser discretas o continuas.

### Variables discretas

Si el número de valores es manejable podemos emplear tablas de frecuencias, como hacíamos con las variables cualitativas. Por otro lado, cuando el número de valores no es manejable (típicamente más de 10), si deseamos emplear tablas de frecuencias, es necesario agrupar en clases como en las variables cuantitativas.

Como representación gráfica podemos emplear gráficos de barras. Una barra para cada valor, o para cada clase, según el caso. Si el número de valores posibles es muy grande, se pueden resumir como las variables continuas: datos agrupados e histogramas.

Como medida resumen fundamental emplearemos la moda, esto es, el valor más repetido. Además, podemos emplear todas las medidas resumen que definiremos para variables continuas.

### Variables continuas

En el caso de variables continuas, la representación visual más común es el llamado **histograma de frecuencias**. En el eje $x$ se representan intervalos de la variable. En el eje $y$ las frecuencias, relativas o absolutas de cada clase.

Veamos el histograma de la variable `edad` en nuestra base de datos de ejemplo:

```{r hist1}
ggplot(data = bank) +
  geom_histogram(mapping = aes(x = age), binwidth = 5)
```

::: callout-caution
## Ejercicio

¿Qué significan los parámetros de la función que se ha empleado para obtener el histograma?
:::

Es posible obtener mucha información sobre la variable de interés a partir del histograma de frecuencias. Por ejemplo, si la distribución de la variable es (o no) simétrica. Además, podemos estudiar su forma, si es unimodal (un único valor más repetido) o multimodal (dos o más valores). Podemos intuir su distribución, si está se asocia a alguna distribución de probabilidad conocida (típicamente la distribución Normal). Además podemos fijarnos en valores centrales y en valores extremos, mínimo y máximo. De este modo podemos llegar a detectar errores en los datos.

::: callout-caution
## Ejercicio

¿Qué puedes averiguar de la variable `edad` observando su histograma de frecuencias?
:::

A continuación vamos a repasar algunos de los métodos númericos más comunes en el análisis exploratorio de una variable aleatoria continua.

#### Medidas de centralización

**Media aritmética**

La media aritmética se obtiene mediante la siguiente fórmula matemática: $$\bar{x}= \frac{\sum\limits_{i=1}^n x_i}{n}$$

La media artimética representa el centro de gravedad de los datos. Está fuertemente influenciada por observaciones extremas. En el caso de que haya gran dispersión en la variable (es decir, que tome gran cantidad de valores diferentes) entonces la media aritmética es un estadístico poco representativo. Además cumple la siguiente propiedad: la media aritmética mantiene la linealidad. Es decir, si $X$ e $Y$ son dos variables con medias $\bar x$ e $\bar y$ respectivamente:

$$Y = a+ bX \implies \bar y = a + b \bar x$$

```{r media}
mean(bank$age)
```

::: callout-caution
## Ejercicio

La media de la variable edad en el conjunto de datos `bank` es `r round(mean(bank$age),digit=1)` años. ¿Crees que es un buen valor representativo de la variable aleatoria? Observa el histograma de frecuencias.
:::

**Mediana**

La mediana es el valor central de los datos. Es decir, aquel que deja la mitad por encima y la mitad por debajo. Se trata de una medida muy poco influenciada por valores extremos.

Para obtener este valor se ordenamos los datos de menor a mayor:

-   Si el número de datos es impar, el que ocupa la posición central, $[n/2]+1$

-   Si el número de datos es par, la media de los dos valores centrales, $n/2$ y $n/2+1$

::: callout-caution
## Ejercicio

La mediana de la variable edad en el conjunto de datos `bank` es `r median(bank$age)` años. ¿Crees que es un buen valor representativo de la variable aleatoria? ¿Qué significa que su valor sea inferior a la media aritmética?
:::

La mediana aritmética no está afectada por valores extremos. Es poco importante el valor (exacto) de los valores por encima (o por debajo) del valor mediana, lo único importante es que están por encima (o por debajo). En muchas ocasiones es una medida más representativa de los datos que la media aritmética, sin embargo habitualmente es menos conocida por los posibles clientes y por lo tanto, menos empleada. Si la distribución de la variable aleatoria es simétrica, perfectamente simétrica (como por ejemplo en la distribución Normal), entonces la mediana coincide con la media aritmética.

**Moda**

La moda es el valor más frecuente, el más repetido, de todos los valores que toma la variable aleatoria. Puede no ser único. Además, es posible calcular la moda en variables cualitativas.

```{r moda, echo=FALSE}
library(modeest)
moda=mlv(bank$age)
```

::: callout-caution
## Ejercicio

La mediana de la variable edad en el conjunto de datos `bank` es `r moda` años. ¿Crees que es un buen valor representativo de la variable aleatoria?
:::

#### Medidas de posición

El **máximo**, $x_{max}$, y el **mínimo**, $x_{min}$ nos informan de los extremos de los datos. Son valores muy útiles para averiguar valores atípicos. Estos valores atípicos, a veces, son errores de medida o nos ofrecen "pistas" sobre posibles aspectos de la variable que no han sido correctamente recogidos.

::: callout-caution
## Ejercicio

Los valores máximo y mínimo de la variable edad en el conjunto de datos `bank` es `r max(bank$age)` y `r min(bank$age)` años. ¿Detectas algún problema en esos valores? Posiblemente, para responder a esta pregunta tengas que volver a estudiar el origen de los datos en la @sec-datos. En muchas ocasiones es necesario consultar con el experto del dominio sobre la validez (o no) de estos valores.
:::

El **percentil** $P_p$, es el valor que deja por debajo de sí mismo el $p\%$ de los datos, siendo $p$ un valor entre $0$ y $100$

-   Los cuartiles: dividen los datos en cuatro partes:
    -   $Q_1 = P_{25}$
    -   $Q_2 = P_{50}=Mediana$
    -   $Q_3 = P_{75}$

Fíjate que el percentil 50, o cuartil 2, es la **mediana**. También es posible definir los deciles ylos terciles. Los *cuantiles* son como los percentiles pero expresados en tanto por uno, $q_p, 0<p<1$.

De este modo obtenemos los cuartiles de la variable edad en la base de datos `bank`.

```{r posicion}
summary(bank$age)
```

Una posible interpretación es que el $50\%$ de la muestra está entre los `r summary(bank$age)[2]` y los `r summary(bank$age)[5]` años.

#### Medidas de dispersión

Para caracterizar un conjunto de datos, además de las medidas de centralización y de posición, necesitamos medidas que nos den una idea de la dispersión de los datos. Una media puede provenir de datos muy próximos a ella, o muy lejanos. En un caso extremo, una media aritmética puede responder a una variable que toma valores constantes, todos ellos iguales a la media. En ese caso su dispersión es $0$.

**Rango**

El rango es una medida de la dispersión de los datos. Se calcula como la diferencia entre el máximo y el mínimo de la variable.

$$R = \max_i{x_i} - \min_i{x_i}$$ En el caso de ejemplo, el rango de edad para la base de datos de `bank` es: $95-18=77$ años.

**Varianza**

La varianza es una medida de la dispersión de los valores que toma una variable en torno a la media de dicha variable. Si tuviéramos una población con $N$ valores $X_i$ y media $\bar X$:

$$
S^2= \frac{\sum\limits_{i=1}^N (X_i- \bar X)^2}{N}
$$ Para muestras de tamaño $n$, el estimador de la varianza es:

$$
s^2= \frac{\sum\limits_{i=1}^n (x_i- \bar{x})^2}{n-1}
$$

**Desviación típica muestral**

La desviación típica muestra no es más que la raiz cuadrada de la varianza muestral: $$
s= \sqrt{\frac{\sum\limits_{i=1}^n (x_i- \bar{x})^2}{n-1}}= \sqrt{s^2}
$$

Su ventaja respecto a la varianza es que la desviación típica está expresada en las mismas unidades de medida que la variable original. Así, por ejemplo, podemos decir que la desviación típica de la variable edad en la base de datos `bank` es de `r round(sqrt(var(bank$age)), digits=2)` años. También podríamos decir que su varianza es de `r round(sqrt(var(bank$age)), digits=2)`$^2$ $=$ `r round(var(bank$age), digits=2)` pero las unidades serían años al cuadrado y la interpretación es mucho más complicada.

Ambas medidas, varianza y desviación típica, son muy sensibles a datos extremos. Existe un teorema matemático, el llamado teorema de Chebycheff, que dice que al menos el $75\%$ de los valores de una variable aleatoria están entre la media y $+-2$ desviaciones típicas: $(\bar x-2s; \bar x + 2s)$. Es importante recalcar que la varianza no mantiene la transformación lineal. Es decir, si $Y=a+bX$ y la varianza de $X$ es $s_X$, entonces la varianza de $Y$ es: $b^2s^2_X$ y **no** es $a+bs_X$.

De las propiedades de la media y la varianza obtenemos una transformación de las variables aleatorias que será muy útil a la hora de comparar valores en distintas escalas. La transformación recibe el nombre de **Z-score**: $$Z = \frac{X-\bar x}{s},$$ Es decir, a cada valor de la variable original le restamos su media y le dividimos por su desviación típica. Esto nos permite, por ejemplo, comparar indicadores de turismo medidos en diferentes países empleando diferentes escalas.

::: {.callout-tip title="Indicadores"}
Para aprender más sobre indicadores, pregunta al DSLAB.
:::

Ahora que ya conoces los cuartiles, podemos presentar el gráfico de cajas y bigotes, mejor conocido como **boxplot**. Se trata de un gráfico que representa la mediana, y los cuartiles $1$ y $3$ de una variable. Además, muestra dos barreras:

$Q1-1.5\cdot IQR; Q3+1.5\cdot IQR$\
$$\mathit{IQR} = Q_3 - Q_1 $$

Además, es muy útil para detectar *outliers* (observaciones atípicas). Valores fuera de las barreras (por arriba o por abajo).

Observa el boxplot de la variable edad para la base de datos `bank`. Pueden observarse numerosos atípicos. Estas observaciones toman valores de edad "atípicos" en relación con el resto de valores de la variable.

```{r boxplot}
ggplot(bank, aes(y=age) )+
  geom_boxplot()
```

#### Medidas de forma

Anteriormente hemos comentado aspectos de las variables aleatorias en base a su histograma y a su boxplot. Existen medidas para evaluar la simetría y el apuntamiento asociado a la distribución de una variable aleatoria.

**Coeficiente de asimetría**

El coeficiente de asimetría se emplea para ver si los datos son simétricos (mediana = media). Si no, sirve para establecer qué tipo de asimetría presentan los datos. Se calcula como sigue:

$$\gamma_1 = \frac{m_3}{s^3}$$ donde $m_3 = \frac{1}{n}\sum\limits_{i=1}^n(x-\bar x ) ^3$

Y su valor se interpreta de la siguiente forma:

-   $\gamma_1 = 0 \implies$ Simétrica
-   $\gamma_1 < 0 \implies$ Asimétrica negativa (valores bajos menos frecuentes que valores altos)
-   $\gamma_1 > 0 \implies$ Asimétrica positiva (valores bajos más frecuentes que valores altos)

En el ejemplo que estamos estudiando, la variable edad en la base de datos `bank` tenemos:

```{r asim, warning=FALSE}
library(moments)
skewness(bank$age)
```

Y por tanto, dado que el valor del coeficiente de asimetría es mayor que $0$ podemos afirmar que la asimetría es positiva, siendo los valores bajos de la variable más frecuentes que los valores altos.

**Coeficiente de apuntamiento o curtosis**

El coeficiente de apuntamiento, también conocido como *curtosis* mide cómo de "apuntados" son los datos. Es decir, si están (o no) concentrados alrededor de la media. Para evaluarlo se toma como referencia la distribución Normal. La curtosis se calcula como sigue:

$$\gamma_2 = \frac{m_4}{s^4}-3$$ donde $m_4 = \frac{1}{n}\sum\limits_{i=1}^n(x-\bar x ) ^4$

Y su interpretación es:

-   $\gamma_2 = 0 \implies$ Igual que la distribución Normal.
-   $\gamma_2 < 0 \implies$ Más aplastada que la distribución Normal. En este caso se dice que la distribución es *leptocúrtica*.
-   $\gamma_2 > 0 \implies$ Más apuntada que la distribución Normal. En este caso se dice que la distribución es *platicúrtica*.

En el ejemplo que estamos estudiando, la variable edad en la base de datos `bank` tenemos:

```{r asim2, warning=FALSE}
kurtosis(bank$age)-3
```

Y por tanto, dado que el valor del coeficiente de asimetría es mayor que $0$ podemos afirmar que la distribución de la variable es más apuntada que la distribución Normal.

## Resumen numérico

En el EDA es muy habitual pedir un resumen numérico con numerosas medidas. En `R` podemos conseguirlo facilmente:

```{r resumen0, message=FALSE}
summary(bank)
```

Si nos centramos en variables continuas, podemos conseguirlo como sigue:

```{r resumen1, message=FALSE}
library(summarytools)
library(knitr)
library(dplyr)
bank %>% 
  select(age, balance,duration,campaign,pdays,previous) %>% 
  descr() |> 
  kable(digits = 2)
```

::: callout-caution
## Ejercicio

Busca el significado de la variable `balance`. Fíjate en el valor de curtosis para dicha variable. ¿Qué interpretación tiene? ¿Crees que el valor de la media es representativo de la variable aleatoria?
:::

## Resumen gráfico

Existen numerosas técnicas, algunas de las cuales se han visto ya. Como por ejemplo, el diagrama de barras para variables cualitativas, el Boxplot o el histograma para variables cauntitativas.

**Diagrama de densidad**

La curva de densidad es una estimación suave de la distribución de probabilidad de una variable cuantitativa. Puede proporcionarte información sobre la simetría y la concentración de los datos.

La siguiente figura presenta la función de densidad de probabilidad de la variable `edad` de la base de datos `bank`.

```{r dens}
ggplot(bank, aes(x = age)) +
geom_density() +
ggtitle('KDE de edad en datos bank')
```

**Diagrama de violín**

El diagrama de violín es una representación gráfica estadística que permite comparar distribuciones de probabilidad. El diagrama de violín combina elementos del diagrama de cajas y bigotes con una representación gráfica de la densidad de probabilidad. Visualmente, se asemeja a un violín, de ahí su nombre. Este gráfico muestra la forma de distribución de los datos y proporciona más información que un simple diagrama de caja.

El aspecto del diagrama responde a:

-   La barra negra gruesa en el centro representa el intervalo intercuartil (IQR), que abarca desde el primer cuartil (Q1) hasta el tercer cuartil (Q3).
-   Las barras negras finas que se extienden desde la barra gruesa representan el 95 % de los intervalos de confianza.
-   El punto blanco dentro del violín es la mediana (valor que divide la distribución en dos partes iguales).
-   A ambos lados del violín, se muestra la densidad de probabilidad, que indica cómo se distribuyen los valores en esa región1.

Este diagrama muestra la distribución completa de los datos, incluyendo detalles sobre la forma (simetría, asimetría, bimodalidad, etc.). Permite detectar valores atípicos y proporciona información sobre la densidad de probabilidad. Es más informativo que un simple diagrama de caja.

La siguiente figura presenta el diagrama de violín de la variable `edad` en función del estado civil de la base de datos `bank`. Además, se ha representado junto con el boxplot por categoría.

```{r dens2}
ggplot(bank, aes(x = marital, y=age,fill=marital)) +
geom_violin(trim=FALSE, alpha=0.5) +
geom_boxplot(width = 0.07)+
scale_fill_manual(values = c("#BCE4D8", "#49A4B9", "#2C5985"))+
theme(legend.position = "none")+
ggtitle('Diagrama de violín de edad en datos bank')
```
